{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwIW5q7Oc6bn"
   },
   "source": [
    "# Section-1\n",
    "**Installing PyMongo and connect to MongoDB**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20750,
     "status": "ok",
     "timestamp": 1704247477712,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "5wDmy7qqEFY2",
    "outputId": "e60703eb-87cd-4957-c926-c26c9c185f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1704247559018,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "4CxVULe5p9od"
   },
   "outputs": [],
   "source": [
    "abs_path = '/content/drive/MyDrive/CA_Repeat'\n",
    "download = '/content/drive/MyDrive/CA_Repeat/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20867,
     "status": "ok",
     "timestamp": 1704247582727,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "uwT1qNU1D-8K",
    "outputId": "fe7eb630-adf3-44b1-dd71-14e192d91f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.0/715.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pykerberos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pymongo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq \"pymongo[snappy,gssapi,srv,tls]\"==3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1666,
     "status": "ok",
     "timestamp": 1704247615089,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "RuuVFBYF3ORv",
    "outputId": "b6622f1d-b2fe-4f8d-c082-7baea32ac0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "\n",
    "uri = \"mongodb+srv://2023120:Adminkhi123@cluster0.fzcw7s3.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# uri = \"mongodb+srv://2023120:Adminkhi123@cluster0.fzcw7s3.mongodb.net/TweetsDB\"\n",
    "\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "\tclient.admin.command('ping')\n",
    "\tprint(\"Successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "\tprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1704247615090,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "f-49T3gfFYFA"
   },
   "outputs": [],
   "source": [
    "client.list_database_names()\n",
    "db = client['TweetsDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1704247616539,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "wP3GQ7V2f5qy",
    "outputId": "50d10cdc-4c4a-45b3-a948-57da1ece928d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ProjectTweets']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtQrXxQ2dOzY"
   },
   "source": [
    "# Section-2\n",
    "**Writing the ProjectTweets.csv to MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1704247621003,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "25-w_t5qIrfU"
   },
   "outputs": [],
   "source": [
    "# Function to check if a collection exists in MongoDB\n",
    "def collection_exists(db, collection_name):\n",
    "    db = client['TweetsDB']\n",
    "    return collection_name in db.list_collection_names()\n",
    "\n",
    "def CSV_to_MongoDb(db_name, csv_path, col_names):\n",
    "    print('Creating new collection \"ProjectTweets\" in TweetsDB')\n",
    "    mongo_db = client[db_name]\n",
    "    print('Converting into Records ...')\n",
    "    data = pd.read_csv(csv_path, names = col_names).to_dict(orient=\"records\")\n",
    "    print('Writing to MongoDB ...')\n",
    "    mongo_db.ProjectTweets.insert_many(data)\n",
    "    print(f'Successfully saved to collections in mongodb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1704247629353,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "T_BqVmRjfC_U",
    "outputId": "dc857eb6-eca0-4f5f-b244-78796187a0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'ProjectTweets' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Check if the collection exists\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "collection_name = \"ProjectTweets\"\n",
    "\n",
    "if collection_exists('TweetsDB', collection_name):\n",
    "    print(f\"Collection '{collection_name}' already exists.\")\n",
    "\n",
    "else:\n",
    "    CSV_to_MongoDb(db_name = 'TweetsDB',\n",
    "                   csv_path = os.path.join(abs_path, 'ProjectTweets.csv'),\n",
    "                   col_names = ['id', 'datetime', 'query', 'username', 'tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMzD-JMPdkKH"
   },
   "source": [
    "# Section-3\n",
    "\n",
    "**Installing Java, Spark and PySpark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62344,
     "status": "ok",
     "timestamp": 1704247709788,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "yLA4s06RcA5q",
    "outputId": "1e95a405-8056-4bc5-e3d3-2ac4250411ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=365535479138a763aa68a06a563e3095bd414c4c87d3c0333d2dfb9b55d4cef4\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.0\n",
      "Collecting spark-nlp\n",
      "  Downloading spark_nlp-5.2.2-py2.py3-none-any.whl (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.3/547.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-5.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "\n",
    "!pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1704247718578,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "E4FN_L1EpFeJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1704247727694,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "mgQrLMCdrGRX"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 34950,
     "status": "ok",
     "timestamp": 1704247764912,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "ca9ZVb0PphUA"
   },
   "outputs": [],
   "source": [
    "#Start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"MySparkSession\") \\\n",
    "    .config(\"spark.driver.memory\",\"4G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1G\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 3587,
     "status": "ok",
     "timestamp": 1704247768470,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "f5vm5T1ZUpzu",
    "outputId": "58034b08-41b1-4bca-f5d9-16a1fec85792"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fc0b7798db70:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MySparkSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d27ea371c90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check status of Spark\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1704247768471,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "m_CLc3tMz0Qu",
    "outputId": "11a6ec22-6784-4906-e7e8-48d9c0b25bde"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(async (port, path, text, element) => {\n",
       "    if (!google.colab.kernel.accessAllowed) {\n",
       "      return;\n",
       "    }\n",
       "    element.appendChild(document.createTextNode(''));\n",
       "    const url = await google.colab.kernel.proxyPort(port);\n",
       "    const anchor = document.createElement('a');\n",
       "    anchor.href = new URL(path, url).toString();\n",
       "    anchor.target = '_blank';\n",
       "    anchor.setAttribute('data-href', url + path);\n",
       "    anchor.textContent = text;\n",
       "    element.appendChild(anchor);\n",
       "  })(4040, \"/jobs/index.html\", \"https://localhost:4040/jobs/index.html\", window.element)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise Spark Stream via Google Colab\n",
    "from google.colab import output\n",
    "output.serve_kernel_port_as_window(4040, path='/jobs/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 22519,
     "status": "ok",
     "timestamp": 1704247790978,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "ruMod8s5jjTt"
   },
   "outputs": [],
   "source": [
    "# read data from mongodb collection \"questions\" into a dataframe \"df\"\n",
    "TweetsDB = client['TweetsDB']\n",
    "ProjectTweets = TweetsDB['ProjectTweets']\n",
    "projection = {\"datetime\": 1, \"tweets\": 1, \"_id\": 0}\n",
    "CollectionList = list(ProjectTweets.find({}, projection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1704247790979,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "PE1lqte0mSqz",
    "outputId": "6c056ff8-929b-48bd-9e73-4a52f8f53cba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'datetime': 'Mon Apr 06 22:19:45 PDT 2009',\n",
       "  'tweets': \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"},\n",
       " {'datetime': 'Mon Apr 06 22:19:49 PDT 2009',\n",
       "  'tweets': \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"},\n",
       " {'datetime': 'Mon Apr 06 22:19:53 PDT 2009',\n",
       "  'tweets': '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CollectionList[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 41077,
     "status": "ok",
     "timestamp": 1704247832051,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "2sydYSA-j2Hy"
   },
   "outputs": [],
   "source": [
    "SparkDF = spark.createDataFrame(CollectionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11226,
     "status": "ok",
     "timestamp": 1704247843252,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "Z3Jn1kA7sdqD",
    "outputId": "6a02c96b-03c1-4a03-857f-a108962ebe2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|datetime                    |tweets                                                                                                               |\n",
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|Mon Apr 06 22:19:45 PDT 2009|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |\n",
      "|Mon Apr 06 22:19:49 PDT 2009|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |\n",
      "|Mon Apr 06 22:19:53 PDT 2009|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |\n",
      "|Mon Apr 06 22:19:57 PDT 2009|my whole body feels itchy and like its on fire                                                                       |\n",
      "|Mon Apr 06 22:19:57 PDT 2009|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |\n",
      "|Mon Apr 06 22:20:00 PDT 2009|@Kwesidei not the whole crew                                                                                         |\n",
      "|Mon Apr 06 22:20:03 PDT 2009|Need a hug                                                                                                           |\n",
      "|Mon Apr 06 22:20:03 PDT 2009|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |\n",
      "|Mon Apr 06 22:20:05 PDT 2009|@Tatiana_K nope they didn't have it                                                                                  |\n",
      "|Mon Apr 06 22:20:09 PDT 2009|@twittera que me muera ?                                                                                             |\n",
      "|Mon Apr 06 22:20:16 PDT 2009|spring break in plain city... it's snowing                                                                           |\n",
      "|Mon Apr 06 22:20:17 PDT 2009|I just re-pierced my ears                                                                                            |\n",
      "|Mon Apr 06 22:20:19 PDT 2009|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |\n",
      "|Mon Apr 06 22:20:19 PDT 2009|@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |\n",
      "|Mon Apr 06 22:20:20 PDT 2009|@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|\n",
      "|Mon Apr 06 22:20:20 PDT 2009|@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |\n",
      "|Mon Apr 06 22:20:22 PDT 2009|Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |\n",
      "|Mon Apr 06 22:20:25 PDT 2009|about to file taxes                                                                                                  |\n",
      "|Mon Apr 06 22:20:31 PDT 2009|@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |\n",
      "|Mon Apr 06 22:20:34 PDT 2009|@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |\n",
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1704247843252,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "IBviMH1QpguU"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "def TweetCleaner(text):\n",
    "    clean_text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\\\n",
    "                    .lower()\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def StripDateTime(string_):\n",
    "    date_string = string_.replace('PDT', 'UTC')\n",
    "    # Convert string to datetime object\n",
    "    datetime_obj = datetime.strptime(date_string, \"%a %b %d %H:%M:%S %Z %Y\")\n",
    "\n",
    "    # Extract date, time, and day\n",
    "    # timestamp = datetime_obj.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    date = datetime_obj.strftime(\"%Y-%m-%d\")\n",
    "    time = datetime_obj.strftime(\"%H:%M:%S\")\n",
    "    day = datetime_obj.strftime(\"%A\")\n",
    "    return date, time, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1704247843252,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "E3bjBFuBsJzS",
    "outputId": "91cfe5eb-44e1-485c-9a00-3b45d81159d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2009-04-06', '22:19:45', 'Monday')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StripDateTime('Mon Apr 06 22:19:45 PDT 2009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11001,
     "status": "ok",
     "timestamp": 1704247936555,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "SF_8LT4r5jKl",
    "outputId": "df69f1b4-7dca-4653-caa3-015f100d4c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+-------------------------------------------------------------------------------------------------------------+\n",
      "|date               |time    |day   |cleaned_tweet                                                                                                |\n",
      "+-------------------+--------+------+-------------------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 00:00:00|22:19:45|Monday|switchfoot   awww thats a bummer  you shoulda got david carr of third day to do it d                         |\n",
      "|2009-04-06 00:00:00|22:19:49|Monday|is upset that he cant update his facebook by texting it and might cry as a result  school today also blah    |\n",
      "|2009-04-06 00:00:00|22:19:53|Monday|kenichan i dived many times for the ball managed to save 50  the rest go out of bounds                       |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|my whole body feels itchy and like its on fire                                                               |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|nationwideclass no its not behaving at all im mad why am i here because i cant see you all over there        |\n",
      "|2009-04-06 00:00:00|22:20:00|Monday|kwesidei not the whole crew                                                                                  |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|need a hug                                                                                                   |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|loltrish hey  long time no see yes rains a bit only a bit  lol  im fine thanks  hows you                     |\n",
      "|2009-04-06 00:00:00|22:20:05|Monday|tatianak nope they didnt have it                                                                             |\n",
      "|2009-04-06 00:00:00|22:20:09|Monday|twittera que me muera                                                                                        |\n",
      "|2009-04-06 00:00:00|22:20:16|Monday|spring break in plain city its snowing                                                                       |\n",
      "|2009-04-06 00:00:00|22:20:17|Monday|i just repierced my ears                                                                                     |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|caregiving i couldnt bear to watch it  and i thought the ua loss was embarrassing                            |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|octolinz16 it it counts idk why i did either you never talk to me anymore                                    |\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|smarrison i wouldve been the first but i didnt have a gun    not really though zac snyders just a doucheclown|\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|iamjazzyfizzle i wish i got to watch it with you i miss you and iamlilnicki  how was the premiere            |\n",
      "|2009-04-06 00:00:00|22:20:22|Monday|hollis death scene will hurt me severely to watch on film  wry is directors cut not out now                  |\n",
      "|2009-04-06 00:00:00|22:20:25|Monday|about to file taxes                                                                                          |\n",
      "|2009-04-06 00:00:00|22:20:31|Monday|lettya ahh ive always wanted to see rent  love the soundtrack                                                |\n",
      "|2009-04-06 00:00:00|22:20:34|Monday|fakerpattypattz oh dear were you drinking out of the forgotten table drinks                                  |\n",
      "+-------------------+--------+------+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, to_timestamp\n",
    "from pyspark.sql.types import StringType, StructType, StructField\n",
    "\n",
    "# spark_df = SparkDF.alias(\"spark_df\")\n",
    "\n",
    "# Define UDFs for TweetCleaner and StripDateTime\n",
    "tweet_cleaner_udf = udf(lambda text: TweetCleaner(text), StringType())\n",
    "strip_datetime_udf = udf(lambda string_: StripDateTime(string_), StructType([\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"time\", StringType(), True),\n",
    "    StructField(\"day\", StringType(), True)\n",
    "]))\n",
    "\n",
    "# Apply UDFs to the DataFrame\n",
    "spark_df = SparkDF.withColumn(\"datetime_info\", strip_datetime_udf(\"datetime\"))\n",
    "spark_df = spark_df.withColumn(\"cleaned_tweet\", tweet_cleaner_udf(\"tweets\"))\n",
    "\n",
    "# Split the 'datetime_info' column into separate columns\n",
    "spark_df = spark_df.withColumn(\"date\", to_timestamp(spark_df[\"datetime_info.date\"]))\n",
    "spark_df = spark_df.withColumn(\"time\", spark_df[\"datetime_info.time\"])\n",
    "spark_df = spark_df.withColumn(\"day\", spark_df[\"datetime_info.day\"])\n",
    "\n",
    "# Drop the original 'tweet' and 'datetime' columns\n",
    "spark_df = spark_df.drop(\"tweets\", \"datetime\", 'datetime_info')\n",
    "spark_df = spark_df.select(\"date\", 'time', 'day', 'cleaned_tweet')\n",
    "# Display the cleaned DataFrame\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21468,
     "status": "ok",
     "timestamp": 1704247973885,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "GYyfu0dF9N02",
    "outputId": "2b379e0c-00f8-41c7-b425-272a65964670"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "# Define the preprocess_text function as a UDF\n",
    "# Download NLTK resources (stopwords and WordNet)\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text_udf(text):\n",
    "    words = TextBlob(text).words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    processed_text = \" \".join(lemmatized_words)\n",
    "    return processed_text\n",
    "\n",
    "sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10435,
     "status": "ok",
     "timestamp": 1704247995954,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "NZKBAnTn8vtv",
    "outputId": "010aaf86-9241-427c-b389-acba6ef545d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------------------------------------------------------------+\n",
      "|date               |time    |day   |ProcessedTweets                                                           |\n",
      "+-------------------+--------+------+--------------------------------------------------------------------------+\n",
      "|2009-04-06 00:00:00|22:19:45|Monday|switchfoot awww thats bummer shoulda got david carr third day             |\n",
      "|2009-04-06 00:00:00|22:19:49|Monday|upset cant update facebook texting might cry result school today also blah|\n",
      "|2009-04-06 00:00:00|22:19:53|Monday|kenichan dived many time ball managed save 50 rest go bound               |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|whole body feel itchy like fire                                           |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|nationwideclass behaving im mad cant see                                  |\n",
      "|2009-04-06 00:00:00|22:20:00|Monday|kwesidei whole crew                                                       |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|need hug                                                                  |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|loltrish hey long time see yes rain bit bit lol im fine thanks hows       |\n",
      "|2009-04-06 00:00:00|22:20:05|Monday|tatianak nope didnt                                                       |\n",
      "|2009-04-06 00:00:00|22:20:09|Monday|twittera que muera                                                        |\n",
      "|2009-04-06 00:00:00|22:20:16|Monday|spring break plain city snowing                                           |\n",
      "|2009-04-06 00:00:00|22:20:17|Monday|repierced ear                                                             |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|caregiving couldnt bear watch thought ua loss embarrassing                |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|octolinz16 count idk either never talk anymore                            |\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|smarrison wouldve first didnt gun really though zac snyders doucheclown   |\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|iamjazzyfizzle wish got watch miss iamlilnicki premiere                   |\n",
      "|2009-04-06 00:00:00|22:20:22|Monday|hollis death scene hurt severely watch film wry director cut              |\n",
      "|2009-04-06 00:00:00|22:20:25|Monday|file tax                                                                  |\n",
      "|2009-04-06 00:00:00|22:20:31|Monday|lettya ahh ive always wanted see rent love soundtrack                     |\n",
      "|2009-04-06 00:00:00|22:20:34|Monday|fakerpattypattz oh dear drinking forgotten table drink                    |\n",
      "+-------------------+--------+------+--------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the UDF\n",
    "preprocess_text_spark_udf = udf(preprocess_text_udf, StringType())\n",
    "\n",
    "# Apply the UDF to the 'text' column\n",
    "spark_df = spark_df.withColumn(\"ProcessedTweets\", preprocess_text_spark_udf(\"cleaned_tweet\"))\n",
    "spark_df = spark_df.drop('cleaned_tweet')\n",
    "\n",
    "# Display the processed DataFrame\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9840,
     "status": "ok",
     "timestamp": 1704248011410,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "aG4ISlX2uD68",
    "outputId": "a470757c-94bc-442a-f98b-c3ada93538ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------------------------------------------------------------+--------------------+\n",
      "|date               |time    |day   |ProcessedTweets                                                           |sentiment           |\n",
      "+-------------------+--------+------+--------------------------------------------------------------------------+--------------------+\n",
      "|2009-04-06 00:00:00|22:19:45|Monday|switchfoot awww thats bummer shoulda got david carr third day             |0.2                 |\n",
      "|2009-04-06 00:00:00|22:19:49|Monday|upset cant update facebook texting might cry result school today also blah|0.0                 |\n",
      "|2009-04-06 00:00:00|22:19:53|Monday|kenichan dived many time ball managed save 50 rest go bound               |0.5                 |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|whole body feel itchy like fire                                           |0.2                 |\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|nationwideclass behaving im mad cant see                                  |-0.625              |\n",
      "|2009-04-06 00:00:00|22:20:00|Monday|kwesidei whole crew                                                       |0.2                 |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|need hug                                                                  |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|loltrish hey long time see yes rain bit bit lol im fine thanks hows       |0.3416666666666667  |\n",
      "|2009-04-06 00:00:00|22:20:05|Monday|tatianak nope didnt                                                       |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:09|Monday|twittera que muera                                                        |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:16|Monday|spring break plain city snowing                                           |-0.21428571428571427|\n",
      "|2009-04-06 00:00:00|22:20:17|Monday|repierced ear                                                             |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|caregiving couldnt bear watch thought ua loss embarrassing                |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|octolinz16 count idk either never talk anymore                            |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|smarrison wouldve first didnt gun really though zac snyders doucheclown   |0.225               |\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|iamjazzyfizzle wish got watch miss iamlilnicki premiere                   |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:22|Monday|hollis death scene hurt severely watch film wry director cut              |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:25|Monday|file tax                                                                  |0.0                 |\n",
      "|2009-04-06 00:00:00|22:20:31|Monday|lettya ahh ive always wanted see rent love soundtrack                     |0.5                 |\n",
      "|2009-04-06 00:00:00|22:20:34|Monday|fakerpattypattz oh dear drinking forgotten table drink                    |0.0                 |\n",
      "+-------------------+--------+------+--------------------------------------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiment = udf(lambda x: TextBlob(x).sentiment[0])\n",
    "spark.udf.register(\"sentiment\", sentiment)\n",
    "spark_df = spark_df.withColumn('sentiment',sentiment('ProcessedTweets').cast('double'))\n",
    "\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9769,
     "status": "ok",
     "timestamp": 1704248026694,
     "user": {
      "displayName": "Abdul Haseeb",
      "userId": "12685583969822085981"
     },
     "user_tz": 480
    },
    "id": "b6yKoMihvzxa",
    "outputId": "8316c406-fd81-4d88-fa1a-4085e7f6761b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+--------------------+-----------+\n",
      "|               date|    time|   day|     ProcessedTweets|           sentiment|date_column|\n",
      "+-------------------+--------+------+--------------------+--------------------+-----------+\n",
      "|2009-04-06 00:00:00|22:19:45|Monday|switchfoot awww t...|                 0.2| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:19:49|Monday|upset cant update...|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:19:53|Monday|kenichan dived ma...|                 0.5| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|whole body feel i...|                 0.2| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:19:57|Monday|nationwideclass b...|              -0.625| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:00|Monday| kwesidei whole crew|                 0.2| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|            need hug|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:03|Monday|loltrish hey long...|  0.3416666666666667| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:05|Monday| tatianak nope didnt|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:09|Monday|  twittera que muera|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:16|Monday|spring break plai...|-0.21428571428571427| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:17|Monday|       repierced ear|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|caregiving couldn...|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:19|Monday|octolinz16 count ...|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|smarrison wouldve...|               0.225| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:20|Monday|iamjazzyfizzle wi...|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:22|Monday|hollis death scen...|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:25|Monday|            file tax|                 0.0| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:31|Monday|lettya ahh ive al...|                 0.5| 2009-04-06|\n",
      "|2009-04-06 00:00:00|22:20:34|Monday|fakerpattypattz o...|                 0.0| 2009-04-06|\n",
      "+-------------------+--------+------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "spark_df = spark_df.withColumn(\"date_column\", to_date(spark_df[\"date\"], \"MM-dd-yyyy\").cast(DateType()))\n",
    "\n",
    "spark_df.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
